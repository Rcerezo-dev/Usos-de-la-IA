{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa95a63",
   "metadata": {},
   "source": [
    "# 1. Identificación del problema:\n",
    "\n",
    "*Contexto* En mi trabajo como profesor de inglés, encuentro 2 tareas terriblemente tediosas que consumen tiempo que no tengo: \n",
    "Preparar nuevos contenidos y corregir tareas.\n",
    "El feedback para mis estudiantes es una parte fundamental para mejorar sus capacidades en inglés, por lo que vamos a crear una herramienta que solucione el problema 2.\n",
    "*Frecuencia*: Esta tarea la realizo de manera semanal, por lo que si esto tiene un buen resultado, puede ayudarme ahorrando tiempo de trabajo FUERA del instituto, dándome tiempo libre para hacer actividades o terminar mi bootcamp\n",
    "\n",
    "*Intentos previos*: Mis intentos previos han funcionado, pasándole a la API de Chatgpt estos archivos, de manera que tardo un poco más, aunque también creo que esto me lleva a revisar más en profundidad (es fácil comprobar errores, o ver problemas al puntuar. Además, no siempre los estudiantes entregan la tarea en el formato pedido, o suben una foto con los ejercicios hechos a cuaderno)\n",
    "\n",
    "\n",
    "# 2. Planificación de la solución\n",
    "\n",
    "*Capacidades del LLM que aprovecharemos*:\n",
    "- Lectura y comprensión de texto\n",
    "- Razonamiento y toma de decisiones\n",
    "- Generación de texto \n",
    "\n",
    "*Flujo de mi solución*\n",
    "\n",
    "Dado que no tenemos un API key que nos permita integrar Moodle con nuestra herramienta, la idea es la siguiente: crear una carpeta donde añadamos todos los archivos de los estudiantes, crear un workflow con el que :\n",
    "\n",
    "- Demos la tarea y el nivel a nuestro agente.\n",
    "- especifiquemos la ruta para que nuestro agente lea todos estos documentos\n",
    "- Antes de empezar a evaluar, que el agente vea el nivel general de la clase para ajustar las puntuaciones \n",
    "- Genere un documento final por alumno\n",
    "<pre>\n",
    "┌──────────────────────────┐\n",
    "│  Configuración inicial   │\n",
    "│  - Ruta de la tarea      │\n",
    "│  - Nivel / rúbrica       │\n",
    "└─────────────┬────────────┘\n",
    "              │\n",
    "┌─────────────▼────────────┐\n",
    "│  Carga de trabajos       │\n",
    "│  (DOCX desde carpeta)    │\n",
    "└─────────────┬────────────┘\n",
    "              │\n",
    "┌─────────────▼────────────┐\n",
    "│  Construcción del estado │\n",
    "│  - Todos los trabajos    │\n",
    "│  - Rúbrica               │\n",
    "└─────────────┬────────────┘\n",
    "              │\n",
    "┌─────────────▼────────────┐\n",
    "│  Análisis global de la   │\n",
    "│  clase (LLM)             │\n",
    "│                          │\n",
    "│  - Nivel medio           │\n",
    "│  - Errores comunes       │\n",
    "│  - Aspectos logrados     │\n",
    "│  - Diferencias clave     │\n",
    "└─────────────┬────────────┘\n",
    "              │\n",
    "      ┌───────▼────────┐\n",
    "      │ Persistencia   │\n",
    "      │ feedback       │\n",
    "      │ general        │\n",
    "      │ (archivo)      │\n",
    "      └───────┬────────┘\n",
    "              │\n",
    "┌─────────────▼────────────┐\n",
    "│  Evaluación individual   │\n",
    "│  con rúbrica y contexto  │\n",
    "│  (por alumno)            │\n",
    "│                          │\n",
    "│  * Diseño paralelizable  │\n",
    "│    (map / futuro)        │\n",
    "└─────────────┬────────────┘\n",
    "              │\n",
    "┌─────────────▼────────────┐\n",
    "│  Generación de archivos  │\n",
    "│  por alumno              │\n",
    "│  - Nota desglosada       │\n",
    "│  - Feedback personalizado│\n",
    "│  - Carpeta por tarea     │\n",
    "└──────────────────────────┘\n",
    "</pre>\n",
    "\n",
    "    (hecho por chatgpt)\n",
    "\n",
    "# 3. Selección de tecnología:\n",
    "\n",
    "En este caso, creo que la mejor opción es utilizar LangGraph. De esta manera, puedo conseguir hacer procesos en paralelo, como hemos visto en el diagrama anterior. \n",
    "De esta manera, solucionamos dos problemas:\n",
    "- Al tener un contexto del nivel general de la clase, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b683122",
   "metadata": {},
   "source": [
    "# 4. Implementación de la solución\n",
    "En este caso, vamos a abrir todos los archivos de tareas de estudiantes ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd79091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.2.1)\n",
      "Requirement already satisfied: google in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->google) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->google) (4.14.1)\n",
      "Requirement already satisfied: wget in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.2)\n",
      "Requirement already satisfied: openai in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.13.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: pip in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (25.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement openai-client (from versions: none)\n",
      "ERROR: No matching distribution found for openai-client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: getpass4 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.14.1)\n",
      "Requirement already satisfied: caugetch in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from getpass4) (0.0.1)\n",
      "Requirement already satisfied: clipboard in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from getpass4) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from getpass4) (0.4.6)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from getpass4) (1.11.0)\n",
      "Requirement already satisfied: python-docx in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\rammu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-docx) (4.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "El sistema no puede encontrar la ruta especificada.\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [88 lines of output]\n",
      "      C:\\Users\\rammu\\AppData\\Local\\Temp\\pip-build-env-a3ae630a\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "      \n",
      "              By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        corresp(dist, value, root_dir)\n",
      "      C:\\Users\\rammu\\AppData\\Local\\Temp\\pip-build-env-a3ae630a\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist._finalize_license_expression()\n",
      "      C:\\Users\\rammu\\AppData\\Local\\Temp\\pip-build-env-a3ae630a\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      creating build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-311\\pygraphviz\\tests\n",
      "      running egg_info\n",
      "      writing pygraphviz.egg-info\\PKG-INFO\n",
      "      writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "      writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "      reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no files found matching '*.swg'\n",
      "      warning: no files found matching '*.png' under directory 'doc'\n",
      "      warning: no files found matching '*.html' under directory 'doc'\n",
      "      warning: no files found matching '*.txt' under directory 'doc'\n",
      "      warning: no files found matching '*.css' under directory 'doc'\n",
      "      warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "      warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "      warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "      no previously-included directories found matching 'doc\\build'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "      copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-311\\pygraphviz\n",
      "      running build_ext\n",
      "      building 'pygraphviz._graphviz' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pygraphviz\n",
      "error: failed-wheel-build-for-install\n",
      "\n",
      "× Failed to build installable wheels for some pyproject.toml based projects\n",
      "╰─> pygraphviz\n"
     ]
    }
   ],
   "source": [
    "#Instalamos las librerías necesarias\n",
    "!pip install python-dotenv\n",
    "!pip install google\n",
    "!pip install wget\n",
    "!pip install openai\n",
    "!pip install --upgrade pip\n",
    "!pip install openai-client\n",
    "!pip install getpass4\n",
    "!pip install python-docx\n",
    "!pip install -q langgraph langchain langchain-openai\n",
    "!apt-get install -y graphviz graphviz-dev > /dev/null 2>&1\n",
    "!pip install -q pygraphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34175c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "API_KEY = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5017a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda, vamos a definir las funciones para cargar los trabajos y la rúbrica\n",
    "# Abrimos todas las tareas de nuestros estudiantes, habilitando que se puedan abrir docs\n",
    "# hacemos esto porque los pdf no son tan fáciles de manejar\n",
    "\n",
    "from docx import Document\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "#creamos la función para cargar los trabajos\n",
    "def cargar_trabajos_docx(ruta: str | Path) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Lee todos los archivos .docx de una carpeta y devuelve\n",
    "    un diccionario {nombre_archivo: texto}.\n",
    "    \"\"\"\n",
    "    ruta = Path(ruta)\n",
    "    trabajos = {}\n",
    "\n",
    "    for archivo in ruta.glob(\"*.docx\"):\n",
    "        doc = Document(archivo)\n",
    "        texto = \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "        trabajos[archivo.stem] = texto\n",
    "\n",
    "    return trabajos\n",
    "#creamos la función para cargar la rúbrica\n",
    "\n",
    "def cargar_rubrica_docx(ruta: str | Path) -> str:\n",
    "    \"\"\"\n",
    "    Lee un archivo .docx de rúbrica y devuelve su contenido como texto.\n",
    "    \"\"\"\n",
    "    ruta = Path(ruta)\n",
    "\n",
    "    if not ruta.exists():\n",
    "        raise FileNotFoundError(f\"No existe la rúbrica en: {ruta}\")\n",
    "\n",
    "    doc = Document(ruta)\n",
    "    texto = \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "\n",
    "    return texto\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1b1a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trabajos cargados: 3\n"
     ]
    }
   ],
   "source": [
    "#establecemos las rutas y cargamos los trabajos y la rúbrica\n",
    "from pathlib import Path\n",
    "\n",
    "RUTA_TAREAS = Path(\"tareas/Tarea 1\")\n",
    "NOMBRE_TAREA = RUTA_TAREAS.name\n",
    "trabajos = cargar_trabajos_docx(RUTA_TAREAS)\n",
    "rubrica = cargar_rubrica_docx(\"tareas/Rúbricas/rubrica tarea 1.docx\")\n",
    "\n",
    "print(f\"Trabajos cargados: {len(trabajos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d072f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el modelo de lenguaje\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    openai_api_key=\"sk-...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c1025c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el estado de la clase usando TypedDict\n",
    "from typing import TypedDict\n",
    "class EstadoClase(TypedDict):\n",
    "    trabajos: dict[str, str]\n",
    "    rubrica: str\n",
    "    nombre_tarea: str\n",
    "    analisis_global: str | None\n",
    "    evaluaciones: dict[str, str] | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c48fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos el nodo de análisis global\n",
    "from pathlib import Path\n",
    "\n",
    "def nodo_analisis_global(state: EstadoClase) -> EstadoClase:\n",
    "    trabajos_texto = \"\"\n",
    "    for alumno, texto in state[\"trabajos\"].items():\n",
    "        trabajos_texto += f\"\\n---\\n{alumno}:\\n{texto}\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Eres un profesor que analiza el nivel general de una clase.\n",
    "\n",
    "    Analiza:\n",
    "    - Nivel medio del grupo\n",
    "    - Errores comunes\n",
    "    - Aspectos bien trabajados\n",
    "    - Qué diferencia a los mejores de los peores\n",
    "\n",
    "    RÚBRICA:\n",
    "    {state['rubrica']}\n",
    "\n",
    "    TRABAJOS:\n",
    "    {trabajos_texto}\n",
    "\n",
    "    NO evalúes alumnos individualmente.\n",
    "    Haz un análisis global del grupo.\n",
    "\n",
    "    Proporciona el análisis de forma clara y estructurada.\n",
    "    Incluye: Una lista de errores comunes que puedan tener los estudiantes y que puedan ser evaluados\n",
    "    en la asignatura de inglés. (Ejemplo: ¿Hay un error gramatical que se repite? ¿Una palabra mal usada? ¿Construcciones gramaticales calcadas del español?)\n",
    "    Para cada uno, incluye ejemplos extraídos de los trabajos de los estudiantes, mostrando el error y una posible solución o corrección.\n",
    "    No incluyas sólo 3 errores, incluye tantos como creas que se repiten de manera significativa, haciendo que el análisis sea útil para mejorar la enseñanza.\n",
    "    Ten en cuenta que mi intención es usar este análisis para hacer un PowerPoint que me ayude a explicar a los estudiantes en qué deben mejorar, a nivel gramatical, de vocabulario y de estilo de redacción.\n",
    "    \"\"\"\n",
    "\n",
    "    respuesta = llm.invoke(prompt)\n",
    "    analisis = respuesta.content\n",
    "\n",
    "    carpeta = Path(\"evaluaciones\") / state[\"nombre_tarea\"]\n",
    "    carpeta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    archivo_feedback = carpeta / \"feedback_general.txt\"\n",
    "    archivo_feedback.write_text(analisis, encoding=\"utf-8\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"analisis_global\": analisis\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a2f6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos la función para parsear JSON de respuestas LLM. De esta forma, podemos extraer\n",
    "# información estructurada de las respuestas del modelo de lenguaje.\n",
    "import re\n",
    "import json\n",
    "\n",
    "def parsear_json_llm(texto: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extrae el primer bloque JSON válido de un texto.\n",
    "    Lanza error si no encuentra ninguno.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\{.*\\}\", texto, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No se encontró un JSON válido en la respuesta\")\n",
    "    return json.loads(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79e814ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos el nodo de evaluación individual\n",
    "# De esta forma, evaluamos cada trabajo individualmente\n",
    "\n",
    "from pathlib import Path\n",
    "def nodo_evaluacion_individual(state: EstadoClase) -> EstadoClase:\n",
    "    evaluaciones = {}\n",
    "\n",
    "    for alumno, texto in state[\"trabajos\"].items():\n",
    "        prompt = f\"\"\"\n",
    "        Eres un profesor que evalúa trabajos de alumnos.\n",
    "\n",
    "        ANÁLISIS GLOBAL DE LA CLASE:\n",
    "        {state['analisis_global']}\n",
    "\n",
    "        RÚBRICA:\n",
    "        {state['rubrica']}\n",
    "\n",
    "        TRABAJO DEL ALUMNO ({alumno}):\n",
    "        {texto}\n",
    "        Evalúa el trabajo del alumno según la rúbrica y el análisis global de la clase, tomando este como contexto para entender el nivel general y poner notas justas comparativamente\n",
    "\n",
    "        Devuelve EXCLUSIVAMENTE un JSON con esta estructura exacta:\n",
    "\n",
    "        {{\n",
    "          \"nota_final\": número del 1 al 10,\n",
    "          \"criterios\": {{\n",
    "            \"criterio_1\": nombre del criterio, número, \"comentario sobre criterio 1, explicando errores explícitos y añadiendo correcciones y cómo mejorar\",\n",
    "            \"criterio_2\": nombre del criterio, número, \"comentario sobre criterio 2  explicando errores explícitos y añadiendo correcciones y cómo mejorar\",\n",
    "          }},\n",
    "          \"feedback\": \"comentario personalizado para el alumno\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        respuesta = llm.invoke(prompt)\n",
    "\n",
    "        evaluaciones[alumno] = respuesta.content\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"evaluaciones\": evaluaciones\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fbd0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el flujo de trabajo con LangGraph\n",
    "from langgraph.graph import StateGraph\n",
    "graph = StateGraph(EstadoClase)\n",
    "\n",
    "graph.add_node(\"analisis_global\", nodo_analisis_global)\n",
    "graph.add_node(\"evaluar_individual\", nodo_evaluacion_individual)\n",
    "\n",
    "graph.set_entry_point(\"analisis_global\")\n",
    "graph.add_edge(\"analisis_global\", \"evaluar_individual\")\n",
    "graph.set_finish_point(\"evaluar_individual\")\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5bbecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos el flujo de trabajo\n",
    "\n",
    "estado_inicial: EstadoClase = {\n",
    "    \"trabajos\": trabajos,\n",
    "    \"rubrica\": rubrica,\n",
    "    \"nombre_tarea\": RUTA_TAREAS.name,\n",
    "    \"analisis_global\": None,\n",
    "    \"evaluaciones\": None\n",
    "}\n",
    "\n",
    "resultado = workflow.invoke(estado_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "336f2528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALUMNO: alumno1\n",
      "TIPO: <class 'str'>\n",
      "CONTENIDO:\n",
      "{\n",
      "  \"nota_final\": 8.5,\n",
      "  \"criterios\": {\n",
      "    \"criterio_1\": \"Intercultural content and awareness, 1.8, The student has shown a good understanding of the cultural differences between Spain and Portugal. The advice given is practical and useful, and the student has avoided stereotypes. However, the student could have included more reflection on the impact of these cultural differences on communication.\",\n",
      "    \"criterio_2\": \"Practical usefulness of the guide, 1.4, The guide is generally useful and provides clear advice for Spanish speakers visiting Portugal. However, some of the advice is somewhat general and could be more specific. For example, the student could have provided more specific examples of words that have different meanings in Spanish and Portuguese.\",\n",
      "    \"criterio_3\": \"Vocabulary range and appropriacy, 1.9, The student has used a wide range of vocabulary related to culture, communication and social interaction. There are a few minor inaccuracies, such as the incorrect use of the preposition 'with' in the phrase 'speak with a lower tone'.\",\n",
      "    \"criterio_4\": \"Grammar and sentence structure, 1.7, The student has demonstrated a good control of grammatical structures. There are a few errors, such as the incorrect use of the preposition 'with' in the phrase 'speak with a lower tone', but the meaning is generally clear.\",\n",
      "    \"criterio_5\": \"Coherence and organization, 0.9, The guide is well organized and easy to follow. The student has clearly structured the guide into different sections, each with a clear focus.\",\n",
      "    \"criterio_6\": \"Register and tone, 0.45, The student has maintained a consistent and appropriate informative tone throughout the guide. However, there are a few instances where the tone is slightly informal, such as the phrase 'without more to say, enjoy your trip!'\"\n",
      "  },\n",
      "  \"feedback\": \"Well done on your intercultural guide. You have shown a good understanding of the cultural differences between Spain and Portugal and provided useful advice for Spanish speakers visiting Portugal. However, try to avoid making general statements and provide more specific examples where possible. Also, pay attention to your use of prepositions and maintain a formal tone throughout your writing. Keep up the good work!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Mostramos un ejemplo de evaluación\n",
    "for alumno, evaluacion_json in resultado[\"evaluaciones\"].items():\n",
    "    print(\"ALUMNO:\", alumno)\n",
    "    print(\"TIPO:\", type(evaluacion_json))\n",
    "    print(\"CONTENIDO:\")\n",
    "    print(evaluacion_json)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6437ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos las evaluaciones en archivos de texto individuales\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "salida = Path(\"evaluaciones\")\n",
    "salida.mkdir(exist_ok=True)\n",
    "\n",
    "for alumno, evaluacion_json in resultado[\"evaluaciones\"].items():\n",
    "    datos = parsear_json_llm(evaluacion_json)\n",
    "\n",
    "    contenido = f\"\"\"\n",
    "    NOTA FINAL: {datos['nota_final']}\n",
    "\n",
    "    DESGLOSE POR CRITERIOS:\n",
    "    \"\"\"\n",
    "\n",
    "    for criterio, nota in datos[\"criterios\"].items():\n",
    "        contenido += f\"- {criterio}: {nota}\\n\"\n",
    "\n",
    "    contenido += f\"\\nFEEDBACK PERSONALIZADO:\\n{datos['feedback']}\\n\"\n",
    "\n",
    "    archivo = salida / f\"{alumno}.txt\"\n",
    "    archivo.write_text(contenido, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e8160fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos la función para guardar las evaluaciones en archivos de texto individuales\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def guardar_evaluaciones(resultado, carpeta_base=\"evaluaciones\"):\n",
    "    nombre_tarea = resultado[\"nombre_tarea\"]\n",
    "    salida = Path(carpeta_base) / nombre_tarea\n",
    "    salida.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    resultado_final = {}\n",
    "\n",
    "    for alumno, evaluacion_json in resultado[\"evaluaciones\"].items():\n",
    "        datos = parsear_json_llm(evaluacion_json)\n",
    "        resultado_final[alumno] = datos\n",
    "\n",
    "        contenido = f\"\"\"\n",
    "NOTA FINAL: {datos['nota_final']}\n",
    "\n",
    "DESGLOSE POR CRITERIOS:\n",
    "\"\"\"\n",
    "        for criterio, nota in datos[\"criterios\"].items():\n",
    "            contenido += f\"- {criterio}: {nota}\\n\"\n",
    "\n",
    "        contenido += f\"\\nFEEDBACK PERSONALIZADO:\\n{datos['feedback']}\\n\"\n",
    "\n",
    "        archivo = salida / f\"{alumno}.txt\"\n",
    "        archivo.write_text(contenido, encoding=\"utf-8\")\n",
    "\n",
    "    return resultado_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b651b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alumno1': {'nota_final': 8.5,\n",
       "  'criterios': {'criterio_1': 'Intercultural content and awareness, 1.8, The student has shown a good understanding of the cultural differences between Spain and Portugal. The advice given is practical and useful, and the student has avoided stereotypes. However, the student could have included more reflection on the impact of these cultural differences on communication.',\n",
       "   'criterio_2': 'Practical usefulness of the guide, 1.4, The guide is generally useful and provides clear advice for Spanish speakers visiting Portugal. However, some of the advice is somewhat general and could be more specific. For example, the student could have provided more specific examples of words that have different meanings in Spanish and Portuguese.',\n",
       "   'criterio_3': \"Vocabulary range and appropriacy, 1.9, The student has used a wide range of vocabulary related to culture, communication and social interaction. There are a few minor inaccuracies, such as the incorrect use of the preposition 'with' in the phrase 'speak with a lower tone'.\",\n",
       "   'criterio_4': \"Grammar and sentence structure, 1.7, The student has demonstrated a good control of grammatical structures. There are a few errors, such as the incorrect use of the preposition 'with' in the phrase 'speak with a lower tone', but the meaning is generally clear.\",\n",
       "   'criterio_5': 'Coherence and organization, 0.9, The guide is well organized and easy to follow. The student has clearly structured the guide into different sections, each with a clear focus.',\n",
       "   'criterio_6': \"Register and tone, 0.45, The student has maintained a consistent and appropriate informative tone throughout the guide. However, there are a few instances where the tone is slightly informal, such as the phrase 'without more to say, enjoy your trip!'\"},\n",
       "  'feedback': 'Well done on your intercultural guide. You have shown a good understanding of the cultural differences between Spain and Portugal and provided useful advice for Spanish speakers visiting Portugal. However, try to avoid making general statements and provide more specific examples where possible. Also, pay attention to your use of prepositions and maintain a formal tone throughout your writing. Keep up the good work!'},\n",
       " 'alumno2': {'nota_final': 8.5,\n",
       "  'criterios': {'criterio_1': 'Intercultural content and awareness, 1.8, El trabajo muestra una comprensión clara de la cultura italiana y su impacto en la vida cotidiana. Sin embargo, podría haber incluido más detalles sobre las diferencias culturales específicas que podrían afectar la comunicación entre los hablantes de español e italiano.',\n",
       "   'criterio_2': 'Practical usefulness of the guide, 1.3, El trabajo proporciona una visión general útil de la cultura italiana, pero podría haber incluido más consejos prácticos para ayudar a los hablantes de español a interactuar de manera apropiada en situaciones reales en Italia.',\n",
       "   'criterio_3': 'Vocabulary range and appropriacy, 1.9, El trabajo demuestra un uso excelente del vocabulario, con una amplia gama de palabras y frases relacionadas con la cultura, la comunicación y la interacción social.',\n",
       "   'criterio_4': 'Grammar and sentence structure, 1.7, El trabajo muestra un buen control de las estructuras gramaticales, aunque hay algunos errores menores que no afectan la comprensión.',\n",
       "   'criterio_5': 'Coherence and organization, 0.9, El trabajo está bien organizado y las ideas se presentan de manera clara y coherente.',\n",
       "   'criterio_6': 'Register and tone, 0.45, El tono del trabajo es en su mayoría apropiado para una guía informativa en inglés, aunque en algunos lugares podría ser un poco más formal.'},\n",
       "  'feedback': 'Buen trabajo en general. Has demostrado una comprensión clara de la cultura italiana y has utilizado un amplio rango de vocabulario. Sin embargo, te animo a que incluyas más detalles específicos sobre las diferencias culturales que podrían afectar la comunicación entre los hablantes de español e italiano, y a que proporcionas más consejos prácticos para interactuar en situaciones reales en Italia. También, recuerda revisar tu trabajo para corregir pequeños errores gramaticales.'},\n",
       " 'alumno3': {'nota_final': 7.5,\n",
       "  'criterios': {'criterio_1': 'Intercultural content and awareness, 1.7, El trabajo muestra una comprensión sólida de la cultura italiana y evita estereotipos. Sin embargo, podría haber incluido más reflexiones sobre cómo estas diferencias culturales pueden afectar la comunicación.',\n",
       "   'criterio_2': 'Practical usefulness of the guide, 1.2, El trabajo proporciona consejos útiles para los viajeros, pero algunos de ellos son un poco generales. Sería útil proporcionar ejemplos más específicos o consejos prácticos.',\n",
       "   'criterio_3': \"Vocabulary range and appropriacy, 1.8, El trabajo muestra un buen uso del vocabulario, con una variedad de palabras y frases utilizadas para expresar ideas. Sin embargo, hay algunos errores, como 'prenderse la comoda,' que es una traducción literal de una frase española que no tiene sentido en inglés.\",\n",
       "   'criterio_4': \"Grammar and sentence structure, 1.4, Hay algunos errores gramaticales y de uso de tiempos verbales, pero en general, el significado es claro. Por ejemplo, 'we know that we dream of enjoying' debería ser 'we dream of enjoying'.\",\n",
       "   'criterio_5': 'Coherence and organization, 0.9, El trabajo está bien organizado y las ideas son claras y coherentes.',\n",
       "   'criterio_6': 'Register and tone, 0.5, El tono es consistente y apropiado para una guía informativa en inglés.'},\n",
       "  'feedback': 'Buen trabajo en general. Has demostrado una buena comprensión de la cultura italiana y has proporcionado información útil para los viajeros. Sin embargo, hay algunos errores gramaticales y de vocabulario que deberías revisar. Además, sería útil proporcionar ejemplos más específicos o consejos prácticos para mejorar la utilidad de tu guía. Sigue trabajando en tus habilidades de escritura en inglés y estoy seguro de que mejorarás aún más.'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardamos las evaluaciones procesadas\n",
    "resultado_final = guardar_evaluaciones(resultado)\n",
    "resultado_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd8d86",
   "metadata": {},
   "source": [
    "# 5. Evaluación y reflexión\n",
    "\n",
    "Me gusta mucho cómo esta herramienta ha funcionado, y cómo, modificando algunas cositas dentro del prompt, y dándole una estructura clara, he conseguido una evaluación bastante buena para todo lo que mis alumnos necesitan. \n",
    "\n",
    "\n",
    "En este caso, he probado con una sóla tarea y distintos alumnos, pero me gustaría probar con más (Aunque no quiero gastar infinitos tokens)\n",
    "\n",
    "la limitación de esta tarea, claramente, podría ser el formato de texto, por lo que implementar un sistema texto a voz para presentaciones podría ser interesante. \n",
    "\n",
    "Esta solución puede ayudarme a ahorrar mucho tiempo de mi trabajo, y utilizarlo exclusivamente para tareas que tengan que ver con ayudar a alumnos. Además, al darme un feedback con visión general, puedo utilizarla para entender los errores de mis alumnos y repasar contenidos que fallen de manera general. \n",
    "\n",
    "Creo que no ha \"cambiado\" mi percepción sobre las aplicaciones prácticas, pero sí que esta herramienta consigue automatizar el trabajo y eliminar muchos pasos intermedios (evita ir copiando y pegando cada tarea en chatgpt, sino que puedo descargar TODAS las entregas a la vez y pasárselas directamente)\n",
    "Me ha parecido además muy interesante un resultado, y es que después de hacer distintas pruebas para ajustar el prompt, he visto que las notas se mantenían estables (siempre ha puntuado de la misma manera, aunque el feedback fuera distinto). Esto no me ha ocurrido cuando he utilizado la API de Chatgpt para evaluar tareas, por lo que entiendo que al haberle dado un contexto, la herramienta ha conseguido crear notas de una manera coherente. \n",
    "Sin embargo, aún estaría el problema de tener que copiar una a una cada evaluación. Además, he anonimizado cada tarea para evitar que openai tenga datos de alumnos, pero eso también supondría un problema ya que haría más difícil trabajar con esto (aunque codificar cada entrega y luego decodificarla no sería muy difícil\n",
    "\n",
    "Sobre cómo he trabajado, comencé creando mi herramienta pensando en usar runnable.map para hacer un flujo paralelo. Sin embargo, vi que esto podría crear resultados con menos coherencia, por lo que opté por crear un sólo estado individual. Por eso, primero el LLM toma una idea general de cómo es el nivel del grupo, para así poder identificar errores comunes, y establece un marco de referencia\n",
    "Teniendo este contexto, realiza las evaluaciones de forma secuencial e independiente. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e015100",
   "metadata": {},
   "source": [
    "# 6. Escalabilidad:\n",
    "\n",
    "- Crear funciones para evaluar otros formatos de texto y comprobar su validez (¿PDF? ¿OpenOffice? ¿.txt?)\n",
    "- Explorar la posibilidad de automatizar esto aún más integrándolo con Moodle, la plataforma donde se entregan todas las tareas de la Comunidad de Madrid. Probablemente, con una API key podríamos descargar todas las tareas en el mismo directorio en lugar de hacerlo a mano, codificar los nombres de los alumnos (Un NER podría ser una idea) para eliminar cualquier marca dentro de la tarea o en el nombre. \n",
    "- De igual manera, podríamos, una vez creados todos los archivos de evaluación, pasarlos a moodle para que las notas se escriban automáticamente en el perfil del alumno, consiguiendo evitar un montón de trabajo innecesario\n",
    "\n",
    "Visión a largo plazo:\n",
    "Podría integrar esta solución aplicándolo a todos los aspectos de corrección (es decir, como dije antes, utilizar una función texto a voz para corregir presentaciones, o incluso, crear un nodo para corregir tareas de respuesta cerrada, como un solucionario)\n",
    "Además, esta tarea podría servir para otros profesores añadiendo al estado un elemento llamado \"asignatura\" de manera que pudiera servir para corregir tareas de otras asignaturas como marketing o gestión de compra\n",
    "\n",
    "Puerta abierta:\n",
    "- Durante estas vacaciones de navidad, me gustaría explorar la opción de crear un nodo que evalúe si la asignatura es inglés o no: de esta manera, si el llm detecta que la asignatura es otra, debería cambiar la manera de evaluar y crear un nuevo prompt que pasar al nodo de evaluación individual y global.\n",
    "- Además, quiero comprobar cuánto de difícil es hacer esta integración con Moodle\n",
    "- tratar de implementar que acepte distintos formatos de texto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp .venv312)",
   "language": "python",
   "name": "nlp312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
